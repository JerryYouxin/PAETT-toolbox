from utils.CallingContextTree import CallingContextTree, AdditionalData, load_keyMap
from utils.searcher import threadSearch
from utils.Configuration import config
import argparse
import os

import numpy as np

from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import pickle

def make_core(val):
    return val*100000

def make_uncore(val):
    return val*256+val

# [thread, <PAPI counter values>..., energy<not-used>] === <model> ===> [core, uncore, thread]
def predict_frequency(data, args):
    # unpack: data.data = [thread, <PAPI counter values>..., energy<not-used>]
    model = args[0]
    config = args[1]
    papi_num = args[2]
    # the number of metrics is not valid, so ignore this node
    if len(data.data) != 2+papi_num:
        print("Warning: Ignore data:", data, ", as the number of data does not matched user specification!")
        return AdditionalData([0, 0, 0])
    thread = data.data[0]
    metrics = data.data[1:-1]
    inp = []
    for c in range(config.get_min_core(), config.get_max_core()+1):
        for uc in range(config.get_min_uncore(), config.get_max_uncore()+1):
            inp.append([c, uc]+metrics)
    trans = StandardScaler().fit_transform(np.array(inp))
    pred = model.predict(trans)
    j = np.argmin(pred)
    core   = make_core(inp[j][0])
    uncore = make_uncore(inp[j][1])
    return AdditionalData([core, uncore, thread])

# predict frequency command from model
def predict(cct, out_fn, config, model, papi_num):
    cct.processAllDataWith(predict_frequency, [model, config, papi_num])
    with open(out_fn, 'w') as f:
        cct.save(f, delimiter=' ')

def load_model(path):
    model = None
    if os.path.exists(path):
        with open(path, "rb") as f:
            model = pickle.load(f)
    else:
        print("Failed to find model file: '{0}'".format(path))
    return model

def keyToID(key, keyMap):
    #print(key)
    return keyMap[key]

def main():
    parser = argparse.ArgumentParser(description='Execute scripts to generate CCT-aware frequency commands with model prediction.')
    parser.add_argument('--exe', help='executable compiled with powerspector\'s instrumentation', default='./run.sh')
    parser.add_argument('--keymap', help='keymap generated by the powerspector (with detection mode)', default='PAETT.keymap')
    parser.add_argument('--continue', dest='cont', help='skip execution if the output file is already exist.', action='store_true')
    parser.add_argument('--consistant', help='thread configuration is consistant through all CCTs.', action='store_true')
    #parser.add_argument('--ts', help='start number of threads for searching', type=int, default=2)
    parser.add_argument('--ts', help='start number of threads for searching', type=int, default=1)
    parser.add_argument('--te', help='end number of threads for searching', type=int, default=config.get_max_thread())
    parser.add_argument('--step', help='step of number of threads when searching', type=int, default=2)
    parser.add_argument('--out', help='output file', default='predict.cct')
    parser.add_argument('--model', help='path to dumped pickle sklearn model', default='')
    parser.add_argument('--papi', help='PAPI counters needed for model input, only valid when model is provided. Delimited by ","', default='PAPI_BR_NTK,PAPI_LD_INS,PAPI_L2_ICR,PAPI_BR_MSP,PAPI_RES_STL,PAPI_SR_INS,PAPI_L2_DCR')
    args = parser.parse_args()
    # initialization
    model = load_model(args.model)
    if model is None:
        print("Error: --model must be specified!")
        exit(1)
    papi_counters = args.papi.split(',')
    print(papi_counters)
    # begin thread searching
    cct = threadSearch(args.exe, args.keymap, papi_counters, args.ts, args.te, args.step, args.consistant, args.cont, enable_cct=True)
    cct.processAllKeyWith(keyToID, load_keyMap(args.keymap))
    predict(cct, args.out, config, model, len(papi_counters))

if __name__=='__main__':
    main()
