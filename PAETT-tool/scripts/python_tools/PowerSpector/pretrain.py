from .preprocess.dataset import DataSet
from .models import MLPModel, GDBTModel

import os
import shutil
import argparse

models = {
    'MLP': MLPModel,
    'GDBT': GDBTModel
}

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Train pre-defined models from collected metrics (by collect_data)')
    parser.add_argument('--model', help='pre-defined models to train, including '+str(models.keys()), required=True)
    parser.add_argument('--benchmarks', help='collected data generated by collect_data. For multiple data from different benchmarks, split by ",".', default="")
    parser.add_argument('--data', help="data folder containing all collected data from all benchmarks.", default="COLLECT")
    parser.add_argument('--out', help="output model's file name", default=None)
    args = parser.parse_args()

    if args.model not in models.keys():
        print("Error: unknown model: ", args.model)
        print("Error: Should be one of these pre-defined models: ", models.keys())
        exit(1)
    model = models[args.model]()
    model.init()
    
    benchmarks = []
    if args.benchmarks=="":
        if os.path.exists(args.data):
            if os.path.isdir(args.data):
                files = os.listdir(args.data)
                for file in files:
                    if os.path.isdir(file):
                        dataFiles = os.listdir(file)
                        if "metric.out" not in dataFiles:
                            print("INFO: Ignore directory {0} as it doesn't contain metric file (metric.out).".format(file))
                        else:
                            benchmarks.append(args.data + '/' + file)
                    else:
                        print("INFO: Ignore file {0} as it is not a data directory.".format(file)) 
            else:
                print("Error: {0} is not a data directory!".format(args.data))
                exit(1)
        else:
            print("Error: directory '{0}' not exist.".format(args.data))
            exit(1)
    else:
        benchmarks = args.benchmarks.split(',')
    dataset = DataSet(benchmarks, energy_threshold=5, enable_correction=True)
    # LOOCV test
    model.LOOCV_test(dataset, "predresult")
    # train with whole dataset
    model.train(dataset)
    # save
    model.save(args.out)

    
